# -*- coding: utf-8 -*-
"""dm_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z9UTLp_HBDr_yHyyUVKbZebO1al1_5Xd
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from wordcloud import WordCloud
import re
import string
from sklearn import preprocessing
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords 
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import RandomForestClassifier

given_df = pd.read_csv("/content/fake_or_real_news.csv")
fakeN = pd.read_csv("/content/Fake.csv")
trueN = pd.read_csv("/content/True.csv")

given_df.head()

fakeN.head()

trueN.head()

"""### making target variables "labels"
"""

label_encoder = preprocessing.LabelEncoder()
given_df['label']= label_encoder.fit_transform(given_df['label'])

given_df['label'].unique()

fakeN["label"] = 0
trueN["label"] = 1

given_df.head(-10)

fakeN.head()

trueN.head()

given_df.shape

fakeN.shape

trueN.shape

"""### merging true and fake data frames"""

new_df = pd.concat([fakeN, trueN], axis =0 )

new_df.head(-10)

new_df.head(-10)

new_df.isnull().sum()*100/new_df.shape[0]

"""### removing the stop words"""

stop = stopwords.words('english')
given_df['text_without_stopwords'] = given_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))

stop = stopwords.words('english')
new_df['text_without_stopwords'] = new_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))
new_df['title_without_stopwords'] = new_df['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))

given_df.columns

new_df.columns

"""### removing the unnecessary columns"""

given_df = given_df.drop(['ID','text'],axis=1)

new_df = new_df.drop(["title","date","text"], axis = 1)

given_df.columns

new_df.columns

"""### Doing some visaulizations"""

fig = px.pie(data_frame=given_df, names="label",title='Proportion of Real vs. Fake News where 0 indicates fake news and 1 indicates true news')
fig.show()

wc = WordCloud(background_color="black", max_words=100,
               max_font_size=256,
               random_state=42, width=1000, height=1000)
wc.generate(' '.join(given_df["text_without_stopwords"]))
plt.imshow(wc)
plt.axis('off')
plt.show()

fig = px.pie(data_frame=new_df, names="label",title='Proportion of Real vs. Fake News where 0 indicates fake news and 1 indicates true news')
fig.show()

sub_tf_df=new_df.groupby('subject').apply(lambda x:x['subject'].count()).reset_index(name='Counts')
fig = px.bar(sub_tf_df, x="subject", y="Counts",
             color='Counts', barmode='group',
             height=400)
fig.show()

df = pd.concat([given_df, new_df], axis =0 )

df.head(10)

fig = px.pie(data_frame=df, names="label",title='Proportion of Real vs. Fake News where 0 indicates fake news and 1 indicates true news')
fig.show()

df.to_csv('DM_PROJECT_FINAL_DATA')

wc = WordCloud(background_color="black", max_words=100,
               max_font_size=256,
               random_state=42, width=1000, height=1000)
wc.generate(' '.join(new_df["title_without_stopwords"]))
plt.imshow(wc)
plt.axis('off')
plt.show()

wc = WordCloud(background_color="black", max_words=100,
               max_font_size=256,
               random_state=42, width=1000, height=1000)
wc.generate(' '.join(new_df["text_without_stopwords"]))
plt.imshow(wc)
plt.axis('off')
plt.show()

"""### Random sampling from our dataframes"""

given_df = given_df.sample(frac=1)

given_df.head(10)

new_df = new_df.sample(frac = 1)

new_df.head(10)

"""### removal of unnecessary columns at model building"""

new_df = new_df.drop(["subject","title_without_stopwords"],axis=1)

new_df.head()

given_df.head()

given_df.reset_index(inplace = True)
given_df.drop(["index"], axis = 1, inplace = True)

given_df.head()

new_df.reset_index(inplace = True)
new_df.drop(["index"], axis = 1, inplace = True)

new_df.head()

"""### extra text processing function"""

def process_words(text):
    text = text.lower()
    text = re.sub('\[.*?\]', '', text)
    text = re.sub("\\W"," ",text) 
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)    
    return text

given_df["text_without_stopwords"] =given_df["text_without_stopwords"].apply(process_words)

new_df["text_without_stopwords"] =new_df["text_without_stopwords"].apply(process_words)

"""### defining the variables and the labels then splitting the data into test and train data"""

given_x = given_df["text_without_stopwords"]
given_y = given_df["label"]
given_x_train, given_x_test, given_y_train, given_y_test = train_test_split(given_x, given_y, test_size=0.25)

new_x = new_df["text_without_stopwords"]
new_y = new_df["label"]
new_x_train, new_x_test, new_y_train, new_y_test = train_test_split(new_x, new_y, test_size=0.25)

x = df["text_without_stopwords"]
y = df["label"]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)

"""### converting text into vectors"""

vectorization = TfidfVectorizer()
given_vecX_train = vectorization.fit_transform(given_x_train)
given_vecX_test = vectorization.transform(given_x_test)

vectorization = TfidfVectorizer()
new_vecX_train = vectorization.fit_transform(new_x_train)
new_vecX_test = vectorization.transform(new_x_test)

vectorization = TfidfVectorizer()
vecX_train = vectorization.fit_transform(x_train)
vecX_test = vectorization.transform(x_test)

"""### logistic regression model"""

LR = LogisticRegression()
LR.fit(given_vecX_train,given_y_train)

pred_lr=LR.predict(given_vecX_test)
LR.score(given_vecX_test, given_y_test)

print(classification_report(given_y_test, pred_lr))

LR = LogisticRegression()
LR.fit(new_vecX_train,new_y_train)

pred_lr=LR.predict(new_vecX_test)
LR.score(new_vecX_test, new_y_test)

print(classification_report(new_y_test, pred_lr))

LR = LogisticRegression()
LR.fit(vecX_train,y_train)

pred_lr=LR.predict(vecX_test)
LR.score(vecX_test, y_test)

print(classification_report(y_test, pred_lr))

"""### decesion tree model"""

DT = DecisionTreeClassifier()
DT.fit(new_vecX_train, new_y_train)

pred_dt = DT.predict(new_vecX_test)
DT.score(new_vecX_test, new_y_test)

print(classification_report(new_y_test, pred_dt))

DT = DecisionTreeClassifier()
DT.fit(given_vecX_train, given_y_train)

pred_dt = DT.predict(given_vecX_test)
DT.score(given_vecX_test, given_y_test)

print(classification_report(given_y_test, pred_dt))

DT = DecisionTreeClassifier()
DT.fit(vecX_train, y_train)

pred_dt = DT.predict(vecX_test)
DT.score(vecX_test, y_test)

print(classification_report(y_test, pred_dt))

"""### Random forest model"""

RF= RandomForestClassifier(random_state=0)
RF.fit(new_vecX_train, new_y_train)

pred_rf = RF.predict(new_vecX_test)
RF.score(new_vecX_test, new_y_test)

print(classification_report(new_y_test, pred_rf))

RF= RandomForestClassifier(random_state=0)
RF.fit(given_vecX_train, given_y_train)

pred_rf = RF.predict(given_vecX_test)
RF.score(given_vecX_test, given_y_test)

RF= RandomForestClassifier(random_state=0)
RF.fit(vecX_train, y_train)

pred_rf = RF.predict(vecX_test)
RF.score(vecX_test, y_test)

print(classification_report(y_test, pred_rf))

"""### Gradient boosting model"""

GB= GradientBoostingClassifier(random_state=0)
GB.fit(new_vecX_train, new_y_train)

pred_gb = GB.predict(new_vecX_test)
GB.score(new_vecX_test, new_y_test)

print(classification_report(new_y_test, pred_gb))

GB= GradientBoostingClassifier(random_state=0)
GB.fit(given_vecX_train, given_y_train)

pred_gb = GB.predict(given_vecX_test)
GB.score(given_vecX_test, given_y_test)

print(classification_report(given_y_test, pred_gb))

GB= GradientBoostingClassifier(random_state=0)
GB.fit(vecX_train, y_train)

pred_gb = GB.predict(vecX_test)
GB.score(vecX_test, y_test)

print(classification_report(y_test, pred_gb))